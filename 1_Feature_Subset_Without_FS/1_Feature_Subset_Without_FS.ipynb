{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b63749c74768a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T14:37:54.704152Z",
     "start_time": "2025-06-02T14:37:54.696137Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import (roc_curve, auc, precision_score, f1_score, \n",
    "                           matthews_corrcoef, accuracy_score, recall_score,\n",
    "                           confusion_matrix, classification_report)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de49f41e4286fcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T14:37:54.716804Z",
     "start_time": "2025-06-02T14:37:54.714006Z"
    }
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set font family globally\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "dpi = 1000\n",
    "plt.rcParams['figure.dpi'] = dpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cdc30f9c79b08f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T14:37:54.743244Z",
     "start_time": "2025-06-02T14:37:54.740383Z"
    }
   },
   "outputs": [],
   "source": [
    "# Base directory\n",
    "BASE_DIR = \"AttBiLSTM_Analysis_Without_FS\"\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.join(BASE_DIR, 'models'), exist_ok=True)\n",
    "os.makedirs(os.path.join(BASE_DIR, 'plots'), exist_ok=True)\n",
    "os.makedirs(os.path.join(BASE_DIR, 'results'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de31445ecf11d2cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T14:37:54.755596Z",
     "start_time": "2025-06-02T14:37:54.753277Z"
    }
   },
   "outputs": [],
   "source": [
    "# Device setup\n",
    "device = torch.device(\"cpu\")\n",
    "try:\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"MPS device detected, using MPS\")\n",
    "    elif torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(\"CUDA device detected, using CUDA\")\n",
    "    print(f\"Using device: {device}\")\n",
    "except:\n",
    "    print(\"Error detecting device capabilities, defaulting to CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a8a453807e96a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T14:37:55.335897Z",
     "start_time": "2025-06-02T14:37:54.766494Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "print(\"Loading and preparing data...\")\n",
    "try:\n",
    "    data = pd.read_csv('../dataset/Combined_Common_Genes_With_Target_ML.csv')\n",
    "    print(f\"Dataset info:\")\n",
    "    print(f\"Shape: {data.shape}\")\n",
    "    print(f\"Target column: {data.columns[-1]}\")\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = data.iloc[:, :-1].values  # All columns except last\n",
    "    y = data.iloc[:, -1].values   # Last column (target)\n",
    "    \n",
    "    print(f\"Features shape: {X.shape}\")\n",
    "    print(f\"Target shape: {y.shape}\")\n",
    "    \n",
    "    # Check target distribution\n",
    "    unique_targets, counts = np.unique(y, return_counts=True)\n",
    "    print(f\"Target distribution:\")\n",
    "    for target, count in zip(unique_targets, counts):\n",
    "        print(f\"  Class {target}: {count} samples ({count/len(y)*100:.2f}%)\")\n",
    "    \n",
    "    num_classes = len(unique_targets)\n",
    "    num_features = X.shape[1]\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27ef78ae1d4e31f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T14:37:55.397316Z",
     "start_time": "2025-06-02T14:37:55.346031Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data preprocessing and scaling\n",
    "print(\"Preprocessing data...\")\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f43deec36f7b89e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T14:37:55.419056Z",
     "start_time": "2025-06-02T14:37:55.414965Z"
    }
   },
   "outputs": [],
   "source": [
    "# Advanced Attention Mechanism\n",
    "class MultiScaleAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_heads=4):\n",
    "        super(MultiScaleAttention, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = hidden_dim // num_heads\n",
    "        \n",
    "        # Multiple attention heads with different perspectives\n",
    "        self.query_nets = nn.ModuleList([\n",
    "            nn.Linear(hidden_dim, self.head_dim) for _ in range(num_heads)\n",
    "        ])\n",
    "        self.key_nets = nn.ModuleList([\n",
    "            nn.Linear(hidden_dim, self.head_dim) for _ in range(num_heads)\n",
    "        ])\n",
    "        self.value_nets = nn.ModuleList([\n",
    "            nn.Linear(hidden_dim, self.head_dim) for _ in range(num_heads)\n",
    "        ])\n",
    "        \n",
    "        self.output_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        \n",
    "        # Multi-head attention\n",
    "        attention_outputs = []\n",
    "        attention_weights_list = []\n",
    "        \n",
    "        for i in range(self.num_heads):\n",
    "            query = self.query_nets[i](x)  # [batch, seq_len, head_dim]\n",
    "            key = self.key_nets[i](x)\n",
    "            value = self.value_nets[i](x)\n",
    "            \n",
    "            # Compute attention scores\n",
    "            scores = torch.matmul(query, key.transpose(-2, -1)) / np.sqrt(self.head_dim)\n",
    "            attention_weights = F.softmax(scores, dim=-1)\n",
    "            attention_weights_list.append(attention_weights)\n",
    "            \n",
    "            # Apply attention to values\n",
    "            attended = torch.matmul(attention_weights, value)\n",
    "            attention_outputs.append(attended)\n",
    "        \n",
    "        # Concatenate all heads\n",
    "        multi_head_output = torch.cat(attention_outputs, dim=-1)\n",
    "        \n",
    "        # Project and apply residual connection\n",
    "        output = self.output_proj(multi_head_output)\n",
    "        output = self.dropout(output)\n",
    "        output = self.layer_norm(x + output)  # Residual connection\n",
    "        \n",
    "        return output, attention_weights_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7239f668457a4c3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T14:37:55.435186Z",
     "start_time": "2025-06-02T14:37:55.429641Z"
    }
   },
   "outputs": [],
   "source": [
    "# Advanced AttBiLSTM Model\n",
    "class AdvancedAttBiLSTM(nn.Module):\n",
    "    \"\"\"Advanced Attention-based Bidirectional LSTM with custom activation functions\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, num_classes, hidden_dim=128, num_layers=2, dropout=0.3):\n",
    "        super(AdvancedAttBiLSTM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Input projection layer\n",
    "        self.input_projection = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.GELU(),  # GELU activation instead of ReLU\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        # Bidirectional LSTM layers\n",
    "        self.lstm_layers = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            input_size = hidden_dim if i == 0 else hidden_dim * 2\n",
    "            self.lstm_layers.append(\n",
    "                nn.LSTM(\n",
    "                    input_size=input_size,\n",
    "                    hidden_size=hidden_dim,\n",
    "                    num_layers=1,\n",
    "                    bidirectional=True,\n",
    "                    batch_first=True,\n",
    "                    dropout=dropout if i < num_layers - 1 else 0\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # Multi-scale attention mechanism\n",
    "        self.attention = MultiScaleAttention(hidden_dim * 2, num_heads=4)\n",
    "        \n",
    "        # Feature fusion layers\n",
    "        self.feature_fusion = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.Mish(),  # Mish activation function\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.Swish(),  # Swish activation function\n",
    "            nn.Dropout(dropout // 2)\n",
    "        )\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim // 4),\n",
    "            nn.BatchNorm1d(hidden_dim // 4),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout // 2),\n",
    "            nn.Linear(hidden_dim // 4, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize model weights using Xavier/He initialization\"\"\"\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "            elif isinstance(module, nn.LSTM):\n",
    "                for name, param in module.named_parameters():\n",
    "                    if 'weight_ih' in name:\n",
    "                        nn.init.xavier_uniform_(param.data)\n",
    "                    elif 'weight_hh' in name:\n",
    "                        nn.init.orthogonal_(param.data)\n",
    "                    elif 'bias' in name:\n",
    "                        nn.init.zeros_(param.data)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Project input features\n",
    "        x = self.input_projection(x)  # [batch_size, hidden_dim]\n",
    "        x = x.unsqueeze(1)  # [batch_size, 1, hidden_dim] - create sequence dimension\n",
    "        \n",
    "        # Apply LSTM layers\n",
    "        for lstm in self.lstm_layers:\n",
    "            x, _ = lstm(x)  # [batch_size, seq_len, hidden_dim * 2]\n",
    "        \n",
    "        # Apply multi-scale attention\n",
    "        x_attended, attention_weights = self.attention(x)  # [batch_size, seq_len, hidden_dim * 2]\n",
    "        \n",
    "        # Global average pooling and max pooling\n",
    "        avg_pool = torch.mean(x_attended, dim=1)  # [batch_size, hidden_dim * 2]\n",
    "        max_pool, _ = torch.max(x_attended, dim=1)  # [batch_size, hidden_dim * 2]\n",
    "        \n",
    "        # Combine pooled features\n",
    "        combined_features = avg_pool + max_pool  # Element-wise addition\n",
    "        \n",
    "        # Feature fusion\n",
    "        fused_features = self.feature_fusion(combined_features)\n",
    "        \n",
    "        # Final classification\n",
    "        output = self.classifier(fused_features)\n",
    "        \n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4f7341fb0d68b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T14:37:55.446969Z",
     "start_time": "2025-06-02T14:37:55.445030Z"
    }
   },
   "outputs": [],
   "source": [
    "# Custom activation functions\n",
    "class Mish(nn.Module):\n",
    "    \"\"\"Mish activation function: x * tanh(softplus(x))\"\"\"\n",
    "    def forward(self, x):\n",
    "        return x * torch.tanh(F.softplus(x))\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    \"\"\"Swish activation function: x * sigmoid(x)\"\"\"\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9497473061ab03ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T14:37:55.458050Z",
     "start_time": "2025-06-02T14:37:55.456482Z"
    }
   },
   "outputs": [],
   "source": [
    "# Register custom activations\n",
    "nn.Mish = Mish\n",
    "nn.Swish = Swish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f300787eedbc730",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T14:37:55.469146Z",
     "start_time": "2025-06-02T14:37:55.466961Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_data_loaders(X_train, y_train, X_val, y_val, batch_size=32):\n",
    "    \"\"\"Create PyTorch data loaders\"\"\"\n",
    "    # Convert to tensors\n",
    "    X_train_tensor = torch.FloatTensor(X_train)\n",
    "    y_train_tensor = torch.LongTensor(y_train)\n",
    "    X_val_tensor = torch.FloatTensor(X_val)\n",
    "    y_val_tensor = torch.LongTensor(y_val)\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3cb27a2f3b5b27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T14:37:55.485080Z",
     "start_time": "2025-06-02T14:37:55.478275Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=100, patience=15):\n",
    "    \"\"\"Train the AttBiLSTM model with early stopping\"\"\"\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    # Calculate class weights for imbalanced data\n",
    "    class_counts = np.bincount(y_train)\n",
    "    class_weights = torch.FloatTensor([len(y_train) / (len(class_counts) * count) \n",
    "                                     for count in class_counts]).to(device)\n",
    "    \n",
    "    # Loss function with class weights\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    \n",
    "    # Optimizer with different learning rates for different parts\n",
    "    optimizer = optim.AdamW([\n",
    "        {'params': model.input_projection.parameters(), 'lr': 1e-3},\n",
    "        {'params': model.lstm_layers.parameters(), 'lr': 5e-4},\n",
    "        {'params': model.attention.parameters(), 'lr': 1e-3},\n",
    "        {'params': model.feature_fusion.parameters(), 'lr': 1e-3},\n",
    "        {'params': model.classifier.parameters(), 'lr': 1e-3}\n",
    "    ], weight_decay=1e-4)\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=10, verbose=True\n",
    "    )\n",
    "    \n",
    "    # Mixed precision training\n",
    "    use_amp = device.type == \"cuda\"\n",
    "    scaler = GradScaler() if use_amp else None\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        'train_loss': [], 'val_loss': [],\n",
    "        'train_acc': [], 'val_acc': []\n",
    "    }\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}')\n",
    "        for batch_idx, (data, target) in enumerate(pbar):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if use_amp:\n",
    "                with autocast():\n",
    "                    output, _ = model(data)\n",
    "                    loss = criterion(output, target)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                output, _ = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            pred = output.argmax(dim=1)\n",
    "            train_correct += pred.eq(target).sum().item()\n",
    "            train_total += target.size(0)\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'Acc': f'{100.*train_correct/train_total:.2f}%'\n",
    "            })\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output, _ = model(data)\n",
    "                val_loss += criterion(output, target).item()\n",
    "                pred = output.argmax(dim=1)\n",
    "                val_correct += pred.eq(target).sum().item()\n",
    "                val_total += target.size(0)\n",
    "        \n",
    "        # Calculate average losses and accuracies\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        train_acc = 100. * train_correct / train_total\n",
    "        val_acc = 100. * val_correct / val_total\n",
    "        \n",
    "        # Update history\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # Early stopping check\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        print(f'Epoch {epoch+1}: Train Loss: {avg_train_loss:.4f}, '\n",
    "              f'Val Loss: {avg_val_loss:.4f}, Train Acc: {train_acc:.2f}%, '\n",
    "              f'Val Acc: {val_acc:.2f}%')\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f'Early stopping triggered after {epoch+1} epochs')\n",
    "            break\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Load best model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    print(f'Training completed in {training_time:.2f} seconds')\n",
    "    return model, history, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd490c7df97274b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T14:37:55.499977Z",
     "start_time": "2025-06-02T14:37:55.494130Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_detailed_metrics(y_true, y_pred, y_pred_proba):\n",
    "    \"\"\"Calculate comprehensive metrics including TP, TN, FP, FN, TPR, TNR, FPR, FNR\"\"\"\n",
    "    \n",
    "    # Basic metrics\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # For binary classification\n",
    "    if len(np.unique(y_true)) == 2:\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        \n",
    "        # Rates\n",
    "        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0  # Sensitivity/Recall\n",
    "        tnr = tn / (tn + fp) if (tn + fp) > 0 else 0  # Specificity\n",
    "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0  # Fall-out\n",
    "        fnr = fn / (fn + tp) if (fn + tp) > 0 else 0  # Miss rate\n",
    "        \n",
    "        # AUC\n",
    "        fpr_roc, tpr_roc, _ = roc_curve(y_true, y_pred_proba[:, 1])\n",
    "        auc_score = auc(fpr_roc, tpr_roc)\n",
    "        \n",
    "        detailed_metrics = {\n",
    "            'ACC': acc,\n",
    "            'AUC': auc_score,\n",
    "            'PRE': precision,\n",
    "            'SP': tnr,  # Specificity\n",
    "            'SN': tpr,  # Sensitivity\n",
    "            'F1': f1,\n",
    "            'MCC': mcc,\n",
    "            'TPR': tpr,\n",
    "            'FPR': fpr,\n",
    "            'TNR': tnr,\n",
    "            'FNR': fnr,\n",
    "            'TP': int(tp),\n",
    "            'TN': int(tn),\n",
    "            'FP': int(fp),\n",
    "            'FN': int(fn)\n",
    "        }\n",
    "        \n",
    "        roc_data = (fpr_roc, tpr_roc, auc_score)\n",
    "        \n",
    "    else:\n",
    "        # For multiclass classification\n",
    "        # Calculate macro-averaged rates\n",
    "        tpr_list, fpr_list, tnr_list, fnr_list = [], [], [], []\n",
    "        tp_total, tn_total, fp_total, fn_total = 0, 0, 0, 0\n",
    "        \n",
    "        auc_scores = []\n",
    "        roc_curves = []\n",
    "        \n",
    "        for i in range(len(np.unique(y_true))):\n",
    "            # One-vs-Rest for each class\n",
    "            y_true_binary = (y_true == i).astype(int)\n",
    "            y_pred_binary = (y_pred == i).astype(int)\n",
    "            \n",
    "            tn_i = np.sum((y_true_binary == 0) & (y_pred_binary == 0))\n",
    "            fp_i = np.sum((y_true_binary == 0) & (y_pred_binary == 1))\n",
    "            fn_i = np.sum((y_true_binary == 1) & (y_pred_binary == 0))\n",
    "            tp_i = np.sum((y_true_binary == 1) & (y_pred_binary == 1))\n",
    "            \n",
    "            tp_total += tp_i\n",
    "            tn_total += tn_i\n",
    "            fp_total += fp_i\n",
    "            fn_total += fn_i\n",
    "            \n",
    "            tpr_i = tp_i / (tp_i + fn_i) if (tp_i + fn_i) > 0 else 0\n",
    "            tnr_i = tn_i / (tn_i + fp_i) if (tn_i + fp_i) > 0 else 0\n",
    "            fpr_i = fp_i / (fp_i + tn_i) if (fp_i + tn_i) > 0 else 0\n",
    "            fnr_i = fn_i / (fn_i + tp_i) if (fn_i + tp_i) > 0 else 0\n",
    "            \n",
    "            tpr_list.append(tpr_i)\n",
    "            tnr_list.append(tnr_i)\n",
    "            fpr_list.append(fpr_i)\n",
    "            fnr_list.append(fnr_i)\n",
    "            \n",
    "            # ROC curve for each class\n",
    "            fpr_roc, tpr_roc, _ = roc_curve(y_true_binary, y_pred_proba[:, i])\n",
    "            auc_i = auc(fpr_roc, tpr_roc)\n",
    "            auc_scores.append(auc_i)\n",
    "            roc_curves.append((fpr_roc, tpr_roc, auc_i))\n",
    "        \n",
    "        detailed_metrics = {\n",
    "            'ACC': acc,\n",
    "            'AUC': np.mean(auc_scores),\n",
    "            'PRE': precision,\n",
    "            'SP': np.mean(tnr_list),  # Specificity\n",
    "            'SN': np.mean(tpr_list),  # Sensitivity\n",
    "            'F1': f1,\n",
    "            'MCC': mcc,\n",
    "            'TPR': np.mean(tpr_list),\n",
    "            'FPR': np.mean(fpr_list),\n",
    "            'TNR': np.mean(tnr_list),\n",
    "            'FNR': np.mean(fnr_list),\n",
    "            'TP': int(tp_total),\n",
    "            'TN': int(tn_total),\n",
    "            'FP': int(fp_total),\n",
    "            'FN': int(fn_total)\n",
    "        }\n",
    "        \n",
    "        roc_data = roc_curves\n",
    "    \n",
    "    return detailed_metrics, cm, roc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bc0a179cd26334",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T14:37:55.511972Z",
     "start_time": "2025-06-02T14:37:55.508979Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names, save_path):\n",
    "    \"\"\"Plot and save confusion matrix\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Create heatmap\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                square=True, linewidths=0.5, cbar_kws={\"shrink\": .8}, annot_kws={\"size\": 20})\n",
    "    \n",
    "    plt.title('Confusion Matrix of AttBiLSTM Without FS', fontsize=28, pad=20)\n",
    "    plt.xlabel('Predicted Label', fontsize=24)\n",
    "    plt.ylabel('True Label', fontsize=24)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    \n",
    "    # Enhance aesthetics\n",
    "    ax = plt.gca()\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(2)\n",
    "        spine.set_color('black')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=dpi, bbox_inches='tight')\n",
    "    plt.savefig(save_path.replace('.png', '.pdf'), dpi=dpi, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333dcb70bf7fa120",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T14:37:55.524374Z",
     "start_time": "2025-06-02T14:37:55.520987Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_training_curves(history, save_path):\n",
    "    \"\"\"Plot training and validation curves\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Loss curves\n",
    "    ax1.plot(history['train_loss'], 'b-', linewidth=2, label='Training Loss')\n",
    "    ax1.plot(history['val_loss'], 'r-', linewidth=2, label='Validation Loss')\n",
    "    ax1.set_title('Training and Validation Loss of AttBiLSTM Without FS', fontsize=28, pad=20)\n",
    "    ax1.set_xlabel('Epoch', fontsize=24)\n",
    "    ax1.set_ylabel('Loss', fontsize=24)\n",
    "    ax1.legend(fontsize=18)\n",
    "    ax1.grid(False)\n",
    "    \n",
    "    # Accuracy curves\n",
    "    ax2.plot(history['train_acc'], 'b-', linewidth=2, label='Training Accuracy')\n",
    "    ax2.plot(history['val_acc'], 'r-', linewidth=2, label='Validation Accuracy')\n",
    "    ax2.set_title('Training and Validation Accuracy of AttBiLSTM Without FS', fontsize=28, pad=20)\n",
    "    ax2.set_xlabel('Epoch', fontsize=24)\n",
    "    ax2.set_ylabel('Accuracy (%)', fontsize=24)\n",
    "    ax2.legend(fontsize=18)\n",
    "    ax2.grid(False)\n",
    "    \n",
    "    for ax in [ax1, ax2]:\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_linewidth(1.5)\n",
    "            spine.set_color('black')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=dpi, bbox_inches='tight')\n",
    "    plt.savefig(save_path.replace('.png', '.pdf'), dpi=dpi, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91bc3aa4070913d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T14:37:55.536768Z",
     "start_time": "2025-06-02T14:37:55.533518Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_training_loss(history, save_path):\n",
    "    \"\"\"Plot and save training and validation loss curve\"\"\"\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(history['train_loss'], 'b-', linewidth=2, label='Training Loss')\n",
    "    plt.plot(history['val_loss'], 'r-', linewidth=2, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss of AttBiLSTM Without FS', fontsize=28, pad=20)\n",
    "    plt.xlabel('Epoch', fontsize=24)\n",
    "    plt.ylabel('Loss', fontsize=24)\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.grid(False)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(2)\n",
    "        spine.set_color('black')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=dpi, bbox_inches='tight')\n",
    "    plt.savefig(save_path.replace('.png', '.pdf'), dpi=dpi, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc0c15898ba466c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T14:37:55.548307Z",
     "start_time": "2025-06-02T14:37:55.545750Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_training_accuracy(history, save_path):\n",
    "    \"\"\"Plot and save training and validation accuracy curve\"\"\"\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(history['train_acc'], 'b-', linewidth=2, label='Training Accuracy')\n",
    "    plt.plot(history['val_acc'], 'r-', linewidth=2, label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy of AttBiLSTM Without FS', fontsize=28, pad=20)\n",
    "    plt.xlabel('Epoch', fontsize=24)\n",
    "    plt.ylabel('Accuracy (%)', fontsize=24)\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.grid(False)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(2)\n",
    "        spine.set_color('black')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=dpi, bbox_inches='tight')\n",
    "    plt.savefig(save_path.replace('.png', '.pdf'), dpi=dpi, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6d1552ed4b84d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T14:37:55.560472Z",
     "start_time": "2025-06-02T14:37:55.557183Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(roc_data, num_classes, save_path):\n",
    "    \"\"\"Plot ROC curves\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    if num_classes == 2:\n",
    "        # Binary classification\n",
    "        fpr, tpr, auc_score = roc_data\n",
    "        plt.plot(fpr, tpr, 'b-', linewidth=3, \n",
    "                label=f'ROC Curve (AUC = {auc_score:.4f})')\n",
    "    else:\n",
    "        # Multiclass classification\n",
    "        colors = ['blue', 'red', 'green', 'purple', 'orange', 'brown', 'pink', 'gray']\n",
    "        for i, (fpr, tpr, auc_score) in enumerate(roc_data):\n",
    "            color = colors[i % len(colors)]\n",
    "            plt.plot(fpr, tpr, color=color, linewidth=2, \n",
    "                    label=f'Class {i} (AUC = {auc_score:.4f})')\n",
    "    \n",
    "    # Diagonal line\n",
    "    plt.plot([0, 1], [0, 1], 'k--', linewidth=2, alpha=0.7)\n",
    "    \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontsize=24)\n",
    "    plt.ylabel('True Positive Rate', fontsize=24)\n",
    "    plt.title('ROC Curves', fontsize=28, pad=20)\n",
    "    plt.legend(loc=\"lower right\", fontsize=18)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Enhance aesthetics\n",
    "    ax = plt.gca()\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(2)\n",
    "        spine.set_color('black')\n",
    "    \n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=dpi, bbox_inches='tight')\n",
    "    plt.savefig(save_path.replace('.png', '.pdf'), dpi=dpi, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843201a0bf4acca5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T14:37:55.572555Z",
     "start_time": "2025-06-02T14:37:55.569315Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model_architecture(model, file_path):\n",
    "    \"\"\"Save model architecture as text file\"\"\"\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(\"Advanced AttBiLSTM Model Architecture\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Input Dimension: {model.input_dim}\\n\")\n",
    "        f.write(f\"Hidden Dimension: {model.hidden_dim}\\n\")\n",
    "        f.write(f\"Number of Classes: {model.num_classes}\\n\")\n",
    "        f.write(f\"Number of LSTM Layers: {model.num_layers}\\n\\n\")\n",
    "        \n",
    "        f.write(\"Model Architecture:\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        f.write(str(model))\n",
    "        f.write(\"\\n\\n\")\n",
    "        \n",
    "        f.write(\"Model Parameters:\\n\")\n",
    "        f.write(\"-\" * 20 + \"\\n\")\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        \n",
    "        f.write(f\"Total Parameters: {total_params:,}\\n\")\n",
    "        f.write(f\"Trainable Parameters: {trainable_params:,}\\n\")\n",
    "        \n",
    "        f.write(\"\\nLayer-wise Parameter Count:\\n\")\n",
    "        for name, module in model.named_modules():\n",
    "            if len(list(module.children())) == 0:  # Only leaf modules\n",
    "                params = sum(p.numel() for p in module.parameters())\n",
    "                if params > 0:\n",
    "                    f.write(f\"{name}: {params:,} parameters\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a061c1055b2be3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T14:37:55.591443Z",
     "start_time": "2025-06-02T14:37:55.581615Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_complete_analysis():\n",
    "    \"\"\"Run the complete AttBiLSTM analysis pipeline\"\"\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Starting Advanced AttBiLSTM Analysis Pipeline\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader, val_loader = create_data_loaders(X_train, y_train, X_val, y_val, batch_size=32)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = AdvancedAttBiLSTM(\n",
    "        input_dim=num_features,\n",
    "        num_classes=num_classes,\n",
    "        hidden_dim=128,\n",
    "        num_layers=2,\n",
    "        dropout=0.3\n",
    "    )\n",
    "    \n",
    "    print(f\"Model initialized with {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "    \n",
    "    # Train model\n",
    "    print(\"\\nTraining model...\")\n",
    "    trained_model, history, training_time = train_model(\n",
    "        model, train_loader, val_loader, epochs=100, patience=15\n",
    "    )\n",
    "    \n",
    "    # Save model\n",
    "    model_save_path = os.path.join(BASE_DIR, 'models', 'attbilstm_model.pth')\n",
    "    torch.save({\n",
    "        'model_state_dict': trained_model.state_dict(),\n",
    "        'model_config': {\n",
    "            'input_dim': num_features,\n",
    "            'num_classes': num_classes,\n",
    "            'hidden_dim': 128,\n",
    "            'num_layers': 2,\n",
    "            'dropout': 0.3\n",
    "        },\n",
    "        'training_history': history,\n",
    "        'scaler_params': {\n",
    "            'mean_': scaler.mean_.tolist(),\n",
    "            'scale_': scaler.scale_.tolist()\n",
    "        }\n",
    "    }, model_save_path)\n",
    "    print(f\"Model saved to: {model_save_path}\")\n",
    "    \n",
    "    # Save model architecture as text\n",
    "    architecture_path = os.path.join(BASE_DIR, 'models', 'model_architecture.txt')\n",
    "    save_model_architecture(trained_model, architecture_path)\n",
    "    print(f\"Model architecture saved to: {architecture_path}\")\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    print(\"\\nEvaluating on test set...\")\n",
    "    trained_model.eval()\n",
    "    X_test_tensor = torch.FloatTensor(X_test).to(device)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        test_outputs, attention_weights = trained_model(X_test_tensor)\n",
    "        test_probabilities = F.softmax(test_outputs, dim=1).cpu().numpy()\n",
    "        test_predictions = np.argmax(test_probabilities, axis=1)\n",
    "    testing_time = time.time() - start_time\n",
    "    \n",
    "    # Calculate detailed metrics\n",
    "    detailed_metrics, confusion_mat, roc_data = calculate_detailed_metrics(\n",
    "        y_test, test_predictions, test_probabilities\n",
    "    )\n",
    "    \n",
    "    # Add timing information\n",
    "    detailed_metrics['Training Time'] = training_time\n",
    "    detailed_metrics['Testing Time'] = testing_time\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"DETAILED EVALUATION RESULTS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Create results table\n",
    "    results_df = pd.DataFrame([detailed_metrics])\n",
    "    results_df = results_df.round(4)\n",
    "    print(\"\\nMain Metrics:\")\n",
    "    main_metrics = ['ACC', 'AUC', 'PRE', 'SP', 'SN', 'F1', 'MCC', 'Training Time', 'Testing Time']\n",
    "    print(results_df[main_metrics].to_string(index=False))\n",
    "    \n",
    "    print(\"\\nDetailed Classification Metrics:\")\n",
    "    detailed_classification = ['TPR', 'FPR', 'TNR', 'FNR', 'TP', 'TN', 'FP', 'FN']\n",
    "    print(results_df[detailed_classification].to_string(index=False))\n",
    "    \n",
    "    # Save results to CSV\n",
    "    results_path = os.path.join(BASE_DIR, 'results', 'detailed_metrics.csv')\n",
    "    results_df.to_csv(results_path, index=False)\n",
    "    print(f\"\\nResults saved to: {results_path}\")\n",
    "    \n",
    "    # Save training history\n",
    "    history_df = pd.DataFrame(history)\n",
    "    history_path = os.path.join(BASE_DIR, 'results', 'training_history.csv')\n",
    "    history_df.to_csv(history_path, index=False)\n",
    "    print(f\"Training history saved to: {history_path}\")\n",
    "    \n",
    "    # Generate and save plots\n",
    "    print(\"\\nGenerating plots...\")\n",
    "    \n",
    "    # 1. Confusion Matrix\n",
    "    class_names = [f'Class {i}' for i in range(num_classes)]\n",
    "    cm_path = os.path.join(BASE_DIR, 'plots', 'confusion_matrix.png')\n",
    "    plot_confusion_matrix(confusion_mat, class_names, cm_path)\n",
    "    print(f\"Confusion matrix saved to: {cm_path}\")\n",
    "    \n",
    "    # 2. Training Curves\n",
    "    curves_path_loss_curve = os.path.join(BASE_DIR, 'plots', 'loss_curve.png')\n",
    "    curves_path_accuracy_curve = os.path.join(BASE_DIR, 'plots', 'accuracy_curve.png')\n",
    "    plot_training_loss(history, curves_path_loss_curve)\n",
    "    plot_training_accuracy(history, curves_path_accuracy_curve)\n",
    "    print(f\"Training curves saved to: {curves_path_loss_curve, curves_path_accuracy_curve}\")\n",
    "    \n",
    "    # 3. ROC Curves\n",
    "    roc_path = os.path.join(BASE_DIR, 'plots', 'roc_curves.png')\n",
    "    plot_roc_curve(roc_data, num_classes, roc_path)\n",
    "    print(f\"ROC curves saved to: {roc_path}\")\n",
    "    \n",
    "    # Save detailed classification report\n",
    "    class_report = classification_report(y_test, test_predictions, \n",
    "                                       target_names=class_names, \n",
    "                                       output_dict=True)\n",
    "    class_report_df = pd.DataFrame(class_report).transpose()\n",
    "    class_report_path = os.path.join(BASE_DIR, 'results', 'classification_report.csv')\n",
    "    class_report_df.to_csv(class_report_path)\n",
    "    print(f\"Classification report saved to: {class_report_path}\")\n",
    "    \n",
    "    # Save attention weights analysis (sample)\n",
    "    if attention_weights:\n",
    "        attention_analysis_path = os.path.join(BASE_DIR, 'results', 'attention_analysis.txt')\n",
    "        with open(attention_analysis_path, 'w') as f:\n",
    "            f.write(\"Attention Weights Analysis\\n\")\n",
    "            f.write(\"=\" * 30 + \"\\n\\n\")\n",
    "            f.write(f\"Number of attention heads: {len(attention_weights)}\\n\")\n",
    "            f.write(f\"Attention tensor shape: {attention_weights[0].shape}\\n\\n\")\n",
    "            \n",
    "            # Calculate average attention across all samples and heads\n",
    "            avg_attention = torch.mean(torch.stack(attention_weights), dim=0)\n",
    "            f.write(f\"Average attention statistics:\\n\")\n",
    "            f.write(f\"Mean: {torch.mean(avg_attention).item():.6f}\\n\")\n",
    "            f.write(f\"Std: {torch.std(avg_attention).item():.6f}\\n\")\n",
    "            f.write(f\"Min: {torch.min(avg_attention).item():.6f}\\n\")\n",
    "            f.write(f\"Max: {torch.max(avg_attention).item():.6f}\\n\")\n",
    "        \n",
    "        print(f\"Attention analysis saved to: {attention_analysis_path}\")\n",
    "    \n",
    "    # Create summary report\n",
    "    summary_path = os.path.join(BASE_DIR, 'results', 'analysis_summary.txt')\n",
    "    with open(summary_path, 'w') as f:\n",
    "        f.write(\"Advanced AttBiLSTM Analysis Summary\\n\")\n",
    "        f.write(\"=\" * 40 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"Dataset Information:\\n\")\n",
    "        f.write(f\"Total samples: {len(X)}\\n\")\n",
    "        f.write(f\"Number of features: {num_features}\\n\")\n",
    "        f.write(f\"Number of classes: {num_classes}\\n\")\n",
    "        f.write(f\"Training samples: {len(X_train)}\\n\")\n",
    "        f.write(f\"Validation samples: {len(X_val)}\\n\")\n",
    "        f.write(f\"Test samples: {len(X_test)}\\n\\n\")\n",
    "        \n",
    "        f.write(\"Model Configuration:\\n\")\n",
    "        f.write(f\"Hidden dimension: 128\\n\")\n",
    "        f.write(f\"Number of LSTM layers: 2\\n\")\n",
    "        f.write(f\"Dropout rate: 0.3\\n\")\n",
    "        f.write(f\"Total parameters: {sum(p.numel() for p in trained_model.parameters()):,}\\n\\n\")\n",
    "        \n",
    "        f.write(\"Performance Metrics:\\n\")\n",
    "        for metric, value in detailed_metrics.items():\n",
    "            if isinstance(value, (int, float)):\n",
    "                f.write(f\"{metric}: {value:.4f}\\n\")\n",
    "        \n",
    "        f.write(f\"\\nClass distribution in test set:\\n\")\n",
    "        for i, count in enumerate(np.bincount(y_test)):\n",
    "            f.write(f\"Class {i}: {count} samples ({count/len(y_test)*100:.2f}%)\\n\")\n",
    "    \n",
    "    print(f\"Analysis summary saved to: {summary_path}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ANALYSIS COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"All results saved in directory: {BASE_DIR}\")\n",
    "    print(\"\\nFiles generated:\")\n",
    "    print(\"- Models: attbilstm_model.pth, model_architecture.txt\")\n",
    "    print(\"- Results: detailed_metrics.csv, training_history.csv, classification_report.csv\")\n",
    "    print(\"- Plots: confusion_matrix.png/pdf, training_curves.png/pdf, roc_curves.png/pdf\")\n",
    "    print(\"- Analysis: attention_analysis.txt, analysis_summary.txt\")\n",
    "    \n",
    "    return trained_model, detailed_metrics, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8d37d0e788addd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T14:38:16.964396Z",
     "start_time": "2025-06-02T14:37:55.601342Z"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        final_model, final_metrics, final_history = run_complete_analysis()\n",
    "        \n",
    "        # Memory cleanup\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        elif torch.backends.mps.is_available():\n",
    "            torch.mps.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        print(\"\\nMemory cleanup completed.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during analysis: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "    finally:\n",
    "        print(\"Analysis pipeline finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
